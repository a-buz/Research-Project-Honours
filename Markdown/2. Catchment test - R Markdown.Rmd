---
title: "Catchment Test"
author: "Bruce"
date: "1 August 2017"
output: word_document
---
Tidyverse package was used to read the files because it is (slightly) quicker than the norm. 
Sys.time was used to calculate the computation time of the code. 
The rivers files refers to streamflow data from the 222 hydrological reference stations downloaded from the BOM website. 

```{r}
#install.packages("tidyverse")
library(tidyverse)
start.time <- Sys.time()

# Get list of river data
rivers <- list.files("Data/Rivers", full.names = TRUE)
```

An empty dataframe for the resulting data was creating.
The dataframe (river.accuracy) consists of 3 columns: station number, station name and flow_accuracy.
The Accuracy is calculated by dividing the number of Quality Codes listed "A" by the length of the data

```{r, message=FALSE, warning=FALSE}
name <- c("Date", "Flow", "QCode") #name of the columns in river files
river.accuracy <- data.frame(AWRC.Station.Number = rep(NA, length(rivers)), 
                             Station.Name = rep(NA, length(rivers)),
                             Flow.Accuracy = rep(NA, length(rivers))) ##Empty dataframe to store the data in 

for (i in 1:length(rivers)) {
  header <- read_csv(rivers[i], col_names = F, n_max=26)
  river.accuracy[i,1] <- basename(gsub(pattern = "\\.csv$", "", rivers[i])) ##Extract number
  river.accuracy[i,2] <- gsub("\\s*\\([^\\)]+\\)", "", header[15,2]) ##Extract name
  
  riverFile <- read_csv(rivers[i], skip = 27, col_names = name) ##26 = number of non-essential lines
  riverFile$Date <- as.POSIXct(as.character(riverFile$Date), format = "%Y-%m-%d") ##Convert data to POSIXct format
  riverFile <- subset(riverFile, Date >= "1990-01-01" & Date <= "2010-12-31") ##This is our study date
  
  river.accuracy[i,3] <- length(riverFile$QCode[which(riverFile$QCode == "A")])/length(riverFile$QCode)*100
}
```

Afterwards, the data was organised in descending order from the most accurate to the least accurate stations and only those with over 90% accuracy (or more accurately, 'best available data') were retained. The stations corresponding will be used in further to find relevant rainfall and temperature stations. 

```{r}
river.accuracy <- river.accuracy[order(-river.accuracy[,3], river.accuracy[,2], river.accuracy[,1]),]
river.accuracy <- river.accuracy[which(river.accuracy$flow_accuracy > 90),] ###111

end.time <- Sys.time()
time.taken <- end.time - start.time
time.taken ##49.5s

write.csv(river.accuracy, file = "Data/CatchmentQuality.csv", row.names = FALSE)
```
AB: The bottom code seems irrelevant

Testing code quality for Tasmania/NSW - few positive results

##Just taking NSW/TAS - Testing the quality of the codes. 

```{r}
NSW.TAS <- read.csv("Data/hrs_station_details.csv", header = TRUE, skip = 11)
NSW.TAS$AWRC.Station.Number <- as.character(NSW.TAS$AWRC.Station.Number)

Catchments <- NSW.TAS$AWRC.Station.Number[which(NSW.TAS$Jurisdiction == "NSW"|
                                                  NSW.TAS$Jurisdiction == "TAS")]

name <- c("Date", "Flow", "QCode") #name of the columns in river files
river.accuracy <- data.frame(Station_Number = rep(NA, length(Catchments)), 
                             Station_name = rep(NA, length(Catchments)),
                             A = rep(NA, length(Catchments)),
                             B = rep(NA, length(Catchments)),
                             C = rep(NA, length(Catchments)),
                             E = rep(NA, length(Catchments)),
                             G = rep(NA, length(Catchments)))##Empty dataframe to store the data in
```

A, B, C, E, G are quality codes - Access information from water NSW website. 

```{r}
river.accuracy <- river.accuracy[order(-river.accuracy[,3], river.accuracy[,2], river.accuracy[,1]),]
river.accuracy <- river.accuracy[which(river.accuracy$flow_accuracy > 90),] ###111
```

Order with accuracy in descending order - the 90 reflects the cutoff. 